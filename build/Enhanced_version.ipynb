{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import pipeline, T5ForConditionalGeneration, T5Tokenizer\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from googleapiclient.discovery import build\n",
    "import os\n",
    "\n",
    "class ProgressiveNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProgressiveNeuralNetwork, self).__init__()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.zero_shot_classifier = pipeline('zero-shot-classification')\n",
    "\n",
    "        self.qa_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "        self.qa_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "        self.fc1 = nn.Linear(768, 256) \n",
    "        self.fc2 = nn.Linear(256, 128)  \n",
    "        self.fc3 = nn.Linear(128, 64)   \n",
    "        self.fc_out = nn.Linear(64, 3)  \n",
    "        self.cache = defaultdict(str)\n",
    "        self.feedback_log = []\n",
    "\n",
    "        # Check if model weights file exists\n",
    "        self.weights_file = 'model_weights.pth'\n",
    "        if os.path.exists(self.weights_file):\n",
    "            # Load the model weights from the file\n",
    "            self.load_weights()\n",
    "        else:\n",
    "            # Initialize and save new model weights if file doesn't exist\n",
    "            self.save_weights()\n",
    "\n",
    "        self.google_api_key = \"\"  # Replace with your Google Search API key\n",
    "        self.google_search_engine_id = \"\"  # Replace with your search engine ID (cx)\n",
    "\n",
    "    def forward(self, query):\n",
    "        if query in self.cache:\n",
    "            return self.cache[query]  # Return cached response if available\n",
    "\n",
    "        # Tokenize and encode the user query\n",
    "        inputs = self.tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
    "        embeddings = self.bert_model(**inputs).last_hidden_state.mean(dim=1)\n",
    "\n",
    "        # Forward through the progressive layers\n",
    "        x = torch.relu(self.fc1(embeddings))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        intent_logits = self.fc_out(x)\n",
    "        zero_shot_result = self.zero_shot_classifier(query, candidate_labels=[\"General Knowledge\", \"Weather\", \"Stock\"])\n",
    "        print(\"Zero-Shot Classification Result: \", zero_shot_result)\n",
    "        highest_score = max(zero_shot_result['scores'])\n",
    "        predicted_intent = zero_shot_result['labels'][zero_shot_result['scores'].index(highest_score)]\n",
    "\n",
    "        # Set a confidence threshold to prevent low-confidence predictions\n",
    "        confidence_threshold = 0.6\n",
    "        if highest_score < confidence_threshold:\n",
    "            predicted_intent = \"General Knowledge\"  # Default to General Knowledge if confidence is low\n",
    "\n",
    "        print(f\"Predicted Intent: {predicted_intent}\")\n",
    "        if predicted_intent == \"General Knowledge\":\n",
    "            answer = self.generate_answer_wikipedia(query)\n",
    "        elif predicted_intent == \"Weather\":\n",
    "            answer = self.generate_answer_weather(query)\n",
    "        elif predicted_intent == \"Stock\":\n",
    "            answer = self.generate_answer_stock(query)\n",
    "\n",
    "        # Cache the response\n",
    "        self.cache[query] = answer\n",
    "\n",
    "        # Ask user for feedback dynamically (simulate user input here)\n",
    "        user_feedback = input(f\"Was this answer helpful? (yes/no): \").strip().lower()\n",
    "        feedback = 1 if user_feedback == \"yes\" else 0  # Feedback logic (1: Helpful, 0: Not Helpful)\n",
    "\n",
    "        # Log feedback\n",
    "        self.log_feedback(query, feedback)\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def fetch_from_wikipedia(self, query):\n",
    "        \"\"\"Fetch data from Wikipedia, handling disambiguation.\"\"\"\n",
    "        try:\n",
    "            search_results = wikipedia.search(query)\n",
    "            page_title = None\n",
    "            for result in search_results:\n",
    "                if result.lower() == query.lower():\n",
    "                    page_title = result\n",
    "                    break\n",
    "            else:\n",
    "                page_title = search_results[0] if search_results else None\n",
    "\n",
    "            if page_title:\n",
    "                summary = wikipedia.summary(page_title, sentences=5)\n",
    "                return summary\n",
    "            else:\n",
    "                return f\"Error fetching data: No relevant Wikipedia page found for '{query}'\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error fetching data: {str(e)}\"\n",
    "\n",
    "    def generate_answer_wikipedia(self, query):\n",
    "        \"\"\"Fetches information from Wikipedia using the query.\"\"\"\n",
    "        return self.fetch_from_wikipedia(query)\n",
    "\n",
    "    def generate_answer_weather(self, query):\n",
    "        \"\"\"Fetches weather info using OpenWeather API or Google Search as fallback.\"\"\"\n",
    "        try:\n",
    "            city = query.split(\"in\")[-1].strip()\n",
    "            api_key = ''  # Replace with your OpenWeather API key\n",
    "            url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}\"\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                temperature = data[\"main\"][\"temp\"] - 273.15\n",
    "                weather_description = data[\"weather\"][0][\"description\"]\n",
    "                return (f\"The current weather in {city} is {weather_description} \"\n",
    "                        f\"with a temperature of {temperature:.2f}Â°C.\")\n",
    "            else:\n",
    "                print(\"OpenWeather API failed. Using Google Search as fallback.\")\n",
    "                return self.google_search(query)  # Fallback to Google Search\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching weather data: {str(e)}. Using Google Search as fallback.\")\n",
    "            return self.google_search(query)  # Fallback to Google Search\n",
    "\n",
    "    def generate_answer_stock(self, query):\n",
    "        \"\"\"Fetches stock info using Alpha Vantage API or Google Search as fallback.\"\"\"\n",
    "        try:\n",
    "            symbol = query.split()[-1].upper()\n",
    "            api_key = ''  # Replace with your Alpha Vantage API key\n",
    "            url = (f\"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol={symbol}\"\n",
    "                   f\"&apikey={api_key}\")\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "\n",
    "            if \"Global Quote\" in data:\n",
    "                global_quote = data[\"Global Quote\"]\n",
    "                price = global_quote[\"05. price\"]\n",
    "                change = global_quote[\"09. change\"]\n",
    "                percent_change = global_quote[\"10. change percent\"]\n",
    "                return (f\"The current price of {symbol} is ${price}. \"\n",
    "                        f\"Change: {change} ({percent_change}).\")\n",
    "            else:\n",
    "                print(\"Alpha Vantage API failed. Using Google Search as fallback.\")\n",
    "                return self.google_search(query)  # Fallback to Google Search\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching stock data: {str(e)}. Using Google Search as fallback.\")\n",
    "            return self.google_search(query)  # Fallback to Google Search\n",
    "\n",
    "    def google_search(self, query):\n",
    "        \"\"\"Performs a Google Search and returns the top result snippet.\"\"\"\n",
    "        service = build(\"customsearch\", \"v1\", developerKey=self.google_api_key)\n",
    "        result = service.cse().list(q=query, cx=self.google_search_engine_id).execute()\n",
    "\n",
    "        if \"items\" in result and result[\"items\"]:\n",
    "            return result[\"items\"][0][\"snippet\"]\n",
    "        else:\n",
    "            return \"No results found on Google Search.\"\n",
    "\n",
    "    def log_feedback(self, query, feedback):\n",
    "        \"\"\"Logs user feedback to a file for analysis and model adaptation.\"\"\"\n",
    "        feedback_data = {\n",
    "            \"query\": query,\n",
    "            \"feedback\": feedback\n",
    "        }\n",
    "        try:\n",
    "            with open('feedback.json', 'a') as file:\n",
    "                json.dump(feedback_data, file)\n",
    "                file.write('\\n')\n",
    "            print(\"Feedback logged successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error logging feedback: {str(e)}\")\n",
    "\n",
    "        # Store feedback for future adaptation\n",
    "        self.feedback_log.append(feedback)\n",
    "\n",
    "    def update_weights(self, feedback):\n",
    "        \"\"\"Adjusts model weights based on feedback.\"\"\"\n",
    "        feedback_strength = np.mean(self.feedback_log)  # Calculate mean feedback as a strength metric\n",
    "        if feedback_strength > 0.8:  # If positive feedback is strong\n",
    "            print(\"Adjusting weights based on positive feedback.\")\n",
    "            # Example: increase weights of positive actions\n",
    "            with torch.no_grad():\n",
    "                self.fc1.weight += torch.randn_like(self.fc1.weight) * 0.01\n",
    "                self.fc2.weight += torch.randn_like(self.fc2.weight) * 0.01\n",
    "                self.fc3.weight += torch.randn_like(self.fc3.weight) * 0.01\n",
    "\n",
    "        elif feedback_strength < 0.2:  # If negative feedback is strong\n",
    "            print(\"Adjusting weights based on negative feedback.\")\n",
    "            # Example: decrease weights of actions that led to mistakes\n",
    "            with torch.no_grad():\n",
    "                self.fc1.weight -= torch.randn_like(self.fc1.weight) * 0.01\n",
    "                self.fc2.weight -= torch.randn_like(self.fc2.weight) * 0.01\n",
    "                self.fc3.weight -= torch.randn_like(self.fc3.weight) * 0.01\n",
    "\n",
    "    def adapt_to_feedback(self):\n",
    "        \"\"\"Adapts model based on the feedback provided.\"\"\"\n",
    "        if len(self.feedback_log) > 10:  # Adapt after accumulating enough feedback\n",
    "            self.update_weights(self.feedback_log)  # Update model weights based on feedback\n",
    "            self.feedback_log.clear()  # Clear feedback log after adaptation\n",
    "\n",
    "    def save_weights(self):\n",
    "        \"\"\"Saves the model weights to a file.\"\"\"\n",
    "        torch.save({\n",
    "            'fc1_weight': self.fc1.weight,\n",
    "            'fc2_weight': self.fc2.weight,\n",
    "            'fc3_weight': self.fc3.weight\n",
    "        }, self.weights_file)\n",
    "        print(\"Model weights saved successfully.\")\n",
    "\n",
    "    def load_weights(self):\n",
    "        \"\"\"Loads the model weights from a file.\"\"\"\n",
    "        checkpoint = torch.load(self.weights_file)\n",
    "        self.fc1.weight.data = checkpoint['fc1_weight']\n",
    "        self.fc2.weight.data = checkpoint['fc2_weight']\n",
    "        self.fc3.weight.data = checkpoint['fc3_weight']\n",
    "        print(\"Model weights loaded successfully.\")\n",
    "\n",
    "pnn_model = ProgressiveNeuralNetwork()\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    print(f\"Query: {user_query}\")\n",
    "    response = pnn_model(user_query)\n",
    "    print(f\"Response: {response}\\n\")\n",
    "    pnn_model.adapt_to_feedback()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
